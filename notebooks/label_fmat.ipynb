{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d52ddb-8fd7-4d86-893d-c67b042775a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime as dt\n",
    "from itertools import combinations\n",
    "from itertools import accumulate\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8708584-f8f2-41eb-af97-1c8fe63fca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_label(pair, pos_ppi_dict, neg_ppi_dict):\n",
    "    if pair in pos_ppi_dict.values():\n",
    "        return(1)\n",
    "    elif pair in neg_ppi_dict.keys():\n",
    "        return(-1)\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260a8a6d-68f2-41b5-80a0-31fe9870153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_group(pair, pos_ppi_dict, neg_ppi_dict):\n",
    "    group_list = []\n",
    "    for k, v in pos_ppi_dict.items():\n",
    "        if pair in v:\n",
    "            group_list.append(k)\n",
    "    if len(group_list) > 1:\n",
    "        return(group_list)\n",
    "    elif len(group_list) == 1:\n",
    "        return(group_list[0])\n",
    "    elif pair in neg_ppi_dict.keys():\n",
    "        return(neg_ppi_dict.get(pair))\n",
    "    else:\n",
    "        return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651b992e-7b37-44ee-b445-77eaaec79d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_spr_grp(group, super_grp_dict):\n",
    "    if type(group) == list:\n",
    "        return(super_grp_dict.get(group[0]))\n",
    "    else:\n",
    "        return(super_grp_dict.get(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "601b95ff-260c-4f5b-b1e8-97274a6e4fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_groups(lsts):\n",
    "    sets = [set(lst) for lst in lsts if lst]\n",
    "    merged = True\n",
    "    while merged:\n",
    "        merged = False\n",
    "        results = []\n",
    "        while sets:\n",
    "            common, rest = sets[0], sets[1:]\n",
    "            sets = []\n",
    "            for x in rest:\n",
    "                if x.isdisjoint(common):\n",
    "                    sets.append(x)\n",
    "                else:\n",
    "                    merged = True\n",
    "                    common |= x\n",
    "            results.append(common)\n",
    "        sets = results\n",
    "    return(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6153435b-2f23-4dd4-a5f3-a68ef618f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sprgrp_dict(labeled_fmat):\n",
    "    mgroup_list = []\n",
    "    for i in range(len(labeled_fmat)):\n",
    "        group = labeled_fmat['group'][i]\n",
    "        if type(group) == list:\n",
    "            mgroup_list.append(group)\n",
    "    merged = merge_groups(mgroup_list)\n",
    "    super_grp_num = 1\n",
    "    super_grp_dict = dict()\n",
    "    for group in merged:\n",
    "        for old_gnum in group:\n",
    "            super_grp_dict[old_gnum] = super_grp_num\n",
    "        super_grp_num += 1\n",
    "    return(super_grp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39f288b1-8f9d-43e7-8b63-8f82c9b87160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pos_dict(gs_file):\n",
    "    print(f'[{dt.datetime.now()}] Generating grouped positive PPI labels from gold standard complexes ...')\n",
    "    pos_ppi_dict = dict()\n",
    "    group_no = 1\n",
    "    dupes = []\n",
    "    with open(gold_std_file, 'r') as f:\n",
    "        ppis = f.read().splitlines() \n",
    "        for p in ppis:\n",
    "            ogs = p.split(' ')\n",
    "            fsets = [frozenset({i, j}) for i,j in list(combinations(ogs, 2))]\n",
    "            pos_ppi_dict.update({group_no: fsets})\n",
    "            group_no += 1\n",
    "    print(f'[{dt.datetime.now()}] Finished generating positive PPI labels!')\n",
    "    return(pos_ppi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe31237-69c2-4a4e-8066-df1084aacc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_neg_dict(pos_dict):\n",
    "    # get random prots from positive PPIs to make negative PPIs\n",
    "    print(f'[{dt.datetime.now()}] Getting random proteins from positive PPIs to generate negative PPIs ...')\n",
    "    random_prots = set()\n",
    "    for group_no, fsets in pos_dict.items():\n",
    "        prot_set = set()\n",
    "        if len(fsets) > 1:\n",
    "            for pair in fsets:\n",
    "                prot_set.add(list(pair)[0])\n",
    "                prot_set.add(list(pair)[1])\n",
    "            neg_prots = random.sample(list(prot_set), 3)\n",
    "            for p in neg_prots:\n",
    "                random_prots.add(p)\n",
    "    print(f'[{dt.datetime.now()}] Generating negative PPIs ...')\n",
    "    neg_ppis = [frozenset({i, j}) for i,j in list(combinations(random_prots, 2))]\n",
    "\n",
    "    # remove any overlap between neg & pos PPIs\n",
    "    print(f'[{dt.datetime.now()}] Removing overlap between random negative PPIs & positive PPIs ...')\n",
    "    t0 = time.time()\n",
    "    all_pos_ppis = list(pos_dict.values())\n",
    "    flat_pos_ppis = [pair for pair_list in all_pos_ppis for pair in pair_list]\n",
    "    overlap = set(neg_ppis).intersection(set(flat_pos_ppis))\n",
    "    overlap_count = len(overlap)\n",
    "    for i in overlap:\n",
    "        neg_ppis.remove(i)\n",
    "    print(f'[{dt.datetime.now()}] # overlapping negative PPIs found & removed = {overlap_count}; total time: {time.time() - t0} seconds)')\n",
    "    \n",
    "    # get negative PPI splits\n",
    "    num_groups = len(pos_dict)\n",
    "    print(f'[{dt.datetime.now()}] Randomly splitting negative PPIs into {num_groups} groups ...')\n",
    "    neg_cmplx_sizes = [random.randint(2, 30) for x in range(num_groups)]\n",
    "    neg_ppi_grouped = [neg_ppis[x - y: x] for x, y in zip(\n",
    "            accumulate(neg_cmplx_sizes), neg_cmplx_sizes)]\n",
    "    print(f'[{dt.datetime.now()}] # of negative PPI groups =', len(neg_ppi_grouped))\n",
    "    \n",
    "    # get negative PPI groups\n",
    "    print(f'[{dt.datetime.now()}] Generating grouped negative PPI labels ...')\n",
    "    neg_ppi_dict = dict()\n",
    "    group_sizes = []\n",
    "    group_no = 1\n",
    "    for group in neg_ppi_grouped:\n",
    "        group_sizes.append(len(group))\n",
    "        for pair in group:\n",
    "            neg_ppi_dict.update({pair: group_no})\n",
    "        group_no += 1\n",
    "    \n",
    "    print(f'[{dt.datetime.now()}] Finished generating negative PPI labels!')\n",
    "    return(neg_ppi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a4ba3e-bc8a-4fd5-a0df-e168b46b1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fmat(fmat_file, pos_dict, neg_dict):\n",
    "    print(f'[{dt.datetime.now()}] Loading features from {fmat_file}...')\n",
    "    with open(data_dir+fmat_file, 'rb') as handle:\n",
    "        fmat = pickle.load(handle)\n",
    "\n",
    "    print(f'[{dt.datetime.now()}] Formatting feature matrix ID columns & rows ...')\n",
    "    fmat[['ID1','ID2']] = fmat['ID'].str.split(' ',expand=True)\n",
    "    fmat = fmat[fmat['ID2'].notna()]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    # TODO: long step; potentially optimize ..?\n",
    "    print(f'[{dt.datetime.now()}] Labeling feature matrix (takes awhile)...')\n",
    "    fmat['label'] = [match_label(frozenset({i, j}), pos_dict, neg_dict) for i, j in zip(fmat['ID1'], fmat['ID2'])]\n",
    "    fmat['group'] = [match_group(frozenset({i, j}), pos_dict, neg_dict) for i, j in zip(fmat['ID1'], fmat['ID2'])]\n",
    "    print(f'[{dt.datetime.now()}] Total time to label {len(fmat)} rows: {time.time() - t0} seconds')\n",
    "    \n",
    "    num_pos = len(fmat[(fmat['label'] == 1)])\n",
    "    num_neg = len(fmat[(fmat['label'] == -1)])\n",
    "    print(f'[{dt.datetime.now()}] Total # positive PPIs = {num_pos}')\n",
    "    print(f'[{dt.datetime.now()}] Total # negative PPIs = {num_neg}')\n",
    "    return(fmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05cc8c3-d04c-4a8c-b3f2-fc6fccdc8755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fmat_supergrps(labeled_fmat):\n",
    "    print(f'[{dt.datetime.now()}] Generating merged complex groups ...')\n",
    "    sdict = make_sprgrp_dict(labeled_fmat)\n",
    "    print(f'[{dt.datetime.now()}] Labeling non-redundant complex groups ...')\n",
    "    labeled_fmat['super_group'] = [match_spr_grp(i, sdict) for i in labeled_fmat['group']]\n",
    "    return(labeled_fmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27ce2f49-5dd1-421e-8c2f-6e543d4a1635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_fmat(labeled_fmat, drop_overlap_groups=False, shuffle_feats=False, shuffle_rows=False):\n",
    "    # get col names for labels, features\n",
    "    print(f'[{dt.datetime.now()}] Reformatting columns ...')\n",
    "    label_cols = ['ID', 'group', 'super_group', 'label']\n",
    "    feature_cols = [c for c in labeled_fmat.columns.values.tolist() if c not in label_cols]\n",
    "    # optionally shuffle feature order\n",
    "    if shuffle_feats:\n",
    "        print(f'[{dt.datetime.now()}] Shuffling feature columns ...')\n",
    "        random.shuffle(feature_cols)\n",
    "    # reorder columns\n",
    "    fmat_fmt = labeled_fmat[label_cols + feature_cols]\n",
    "    # optionally drop group_col with redundant PPIs\n",
    "    # probably always want to do this tbh\n",
    "    if drop_overlap_groups:\n",
    "        print(f'[{dt.datetime.now()}] Dropping redundant complex groups ...')\n",
    "        fmat_fmt = fmat_fmt.drop(['group'], axis=1)\n",
    "    # optionally shuffle row order;\n",
    "    # --> technically will be done later w/ sklearn.model_selection.GroupShuffleSplit\n",
    "    # --> but it's here if you want to shuffle at this step for some reason\n",
    "    if shuffle_rows:\n",
    "        print(f'[{dt.datetime.now()}] Shuffling non-redundant protein complex super groups ...')\n",
    "        grps = fmat_fmt['super_group'].unique()\n",
    "        random.shuffle(grps)\n",
    "        fmat_fmt = fmat_fmt.set_index('super_group').loc[grps].reset_index()\n",
    "    print('Final feature matrix:')\n",
    "    print(fmat_fmt.head())\n",
    "    return(fmat_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07d9354e-a874-4a90-a5ea-3943ac1fa5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fmat_files(labeled_fmat, fmat_file, outfile=None):\n",
    "    # format outfile path/name if none specified\n",
    "    if not outfile:\n",
    "        plist = fmat_file.split('/', 1)\n",
    "        outpath = '/'.join(plist[:-1])+'/'\n",
    "        outfile = outpath+'labeled_featmat'\n",
    "    \n",
    "    # write out matrices\n",
    "    t0 = time.time()\n",
    "    print(f'[{dt.datetime.now()}] Writing out matrices:')\n",
    "    print(f\"[{dt.datetime.now()}] \\t► Full matrix (labeled + unlabeled) --> {outfile}\")\n",
    "    print(f\"[{dt.datetime.now()}] \\t► Positive & negative PPIs --> {outfile+'_traintest'}\")\n",
    "    print(f\"[{dt.datetime.now()}] \\t► Gold standard (positive) PPIs only --> {outfile+'_goldstd'}\")\n",
    "    \n",
    "    # gold standard (positive/known) PPIs only\n",
    "    t1 = time.time()\n",
    "    print(f'[{dt.datetime.now()}] Extracting gold standard PPIs ...')\n",
    "    goldstd = labeled_fmat[(labeled_fmat['label'] == 1)]\n",
    "    goldstd.reset_index(drop=True, inplace=True)\n",
    "    print(f\"[{dt.datetime.now()}] Writing serialized gold standard matrix to {outfile+'_goldstd.pkl'} ... \")\n",
    "    goldstd.to_pickle(outfile+'_goldstd.pkl')\n",
    "    print(f\"[{dt.datetime.now()}] Writing comma-separated gold standard matrix to {outfile+'_goldstd'} ... \")\n",
    "    goldstd.to_csv(outfile+'_goldstd', index=False)\n",
    "    print(f\"[{dt.datetime.now()}] Total time to write gold standard feature matrix of shape {goldstd.shape}: {time.time() - t1} seconds\")\n",
    "    \n",
    "    # positive + negative PPIs only\n",
    "    t2 = time.time()\n",
    "    print(f'[{dt.datetime.now()}] Extracting train/test rows ...')\n",
    "    traintest = labeled_fmat[(labeled_fmat['label'] == 1) | (labeled_fmat['label'] == -1)]\n",
    "    traintest.reset_index(drop=True, inplace=True)\n",
    "    print(f\"[{dt.datetime.now()}] Writing serialized train/test matrix to {outfile+'_traintest.pkl'} ... \")\n",
    "    traintest.to_pickle(outfile+'_traintest.pkl')\n",
    "    print(f\"[{dt.datetime.now()}] Writing comma-separated train/test matrix to {outfile+'_traintest'} ... \")\n",
    "    traintest.to_csv(outfile+'_traintest', index=False)\n",
    "    print(f\"[{dt.datetime.now()}] Total time to write train/test feature matrix of shape {traintest.shape}: {time.time() - t2} seconds\")\n",
    "    \n",
    "    # all data, labeled & unlabeled\n",
    "    t3 = time.time()\n",
    "    print(f\"[{dt.datetime.now()}] Writing full serialized matrix to {outfile+'.pkl'} ... \")\n",
    "    labeled_fmat.to_pickle(outfile+'.pkl')\n",
    "    print(f\"[{dt.datetime.now()}] Writing full comma-separated matrix to {outfile} ... \")\n",
    "    labeled_fmat.to_csv(outfile, index=False)\n",
    "    print(f\"[{dt.datetime.now()}] Total time to write full feature matrix of shape {labeled_fmat.shape}: {time.time() - t3} seconds\")\n",
    "    \n",
    "    print(f\"[{dt.datetime.now()}] ---------------------------------------------------------\")\n",
    "    print(f\"[{dt.datetime.now()}] Total time to write all files: {time.time() - t0} seconds\")\n",
    "    print(f\"[{dt.datetime.now()}] ---------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe04800-2135-4803-9026-f60721147f4e",
   "metadata": {},
   "source": [
    "## Input vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b81c7119-de35-48d2-9731-effd90e7bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmat_file = '../ppi_ml/data/featmats/featmat.pkl'\n",
    "outfile = '../ppi_ml/data/featmats/featmat_labeled'\n",
    "gold_std_file = '../ppi_ml/data/gold_stds/all.gold.cmplx.noRibos.merged.txt'\n",
    "seed = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c94a48-6e4b-4a85-a8ac-47a8ca8046b9",
   "metadata": {},
   "source": [
    "## Run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eb015ac-9151-4bb1-b0af-65ef273baeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-07 14:53:33.576621] Generating grouped positive PPI labels from gold standard complexes ...\n",
      "[2023-02-07 14:53:33.640402] Finished generating positive PPI labels!\n",
      "[2023-02-07 14:53:33.640601] Getting random proteins from positive PPIs to generate negative PPIs ...\n",
      "[2023-02-07 14:53:33.652776] Generating negative PPIs ...\n",
      "[2023-02-07 14:53:35.963242] Removing overlap between random negative PPIs & positive PPIs ...\n",
      "[2023-02-07 14:56:12.146275] # overlapping negative PPIs found & removed = 6957; total time: 156.18288898468018 seconds)\n",
      "[2023-02-07 14:56:12.146518] Randomly splitting negative PPIs into 1499 groups ...\n",
      "[2023-02-07 14:56:12.150453] # of negative PPI groups = 1499\n",
      "[2023-02-07 14:56:12.150475] Generating grouped negative PPI labels ...\n",
      "[2023-02-07 14:56:12.157232] Finished generating negative PPI labels!\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "pos_dict = make_pos_dict(gold_std_file)\n",
    "neg_dict = make_neg_dict(pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d44e96db-fe5e-44a6-8745-819fb20eeb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-07 14:56:12.252535] Loading features from ../ppi_ml/data/featmats/featmat.pkl...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m labeled_fmat \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_fmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfmat_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m labeled_fmat_final \u001b[38;5;241m=\u001b[39m label_fmat_supergrps(labeled_fmat)\n",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m, in \u001b[0;36mlabel_fmat\u001b[0;34m(fmat_file, pos_dict, neg_dict)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlabel_fmat\u001b[39m(fmat_file, pos_dict, neg_dict):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Loading features from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfmat_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mdata_dir\u001b[49m\u001b[38;5;241m+\u001b[39mfmat_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m      4\u001b[0m         fmat \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Formatting feature matrix ID columns & rows ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "labeled_fmat = label_fmat(fmat_file, pos_dict, neg_dict)\n",
    "labeled_fmat_final = label_fmat_supergrps(labeled_fmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f288d9-01ab-4c55-9111-6b7d44942ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fmat_out = format_fmat(labeled_fmat_final, drop_overlap_groups=True, shuffle_feats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c15c8c-9863-4858-b4da-566a06c5e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_fmat_files(fmat_out, fmat_file, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19eff2-8e10-4f87-bda4-a1cb73c3339c",
   "metadata": {},
   "source": [
    "## Checks & balances below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4c1c9-be40-4ec8-ae1d-e175dded35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "multi_count = 0\n",
    "for i in range(len(fmat_out)):\n",
    "    group = fmat_out['super_group'][i]\n",
    "    if type(group) == list:\n",
    "        index_list.append(i)\n",
    "        multi_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6406a-d57e-4318-955b-a53496c74c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4535e8e-e31e-4bfe-9891-9328b1cd83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_check = random.choice(list(pos_dict.values()))\n",
    "neg_check = random.choice(list(neg_dict.keys()))\n",
    "print(pos_check)\n",
    "print(neg_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f1655-8d56-4150-8ed5-2a8599bee45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fmat_out[fmat_out['label'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc652e-ea00-45fd-b8ee-9f7df43c666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fmat_out[fmat_out['label'] == -1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
