{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83a5894-49d4-4966-b9d5-a348a9f3115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from functools import reduce\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b80887-4109-4080-aa42-db2e79be5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/'\n",
    "pep_files = [f for f in os.listdir(data_dir) if re.match('.*prot_list$', f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff64edc7-0255-4d17-8453-d2048168364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_data(file):\n",
    "    # read in .prot_count file\n",
    "    print(f'Processing {file} ...')\n",
    "    df = pd.read_csv(file, sep='\\t', header=None)\n",
    "\n",
    "    # extract & format peptides \n",
    "    pep_list = []\n",
    "    for i in df.iloc[:, 0]:\n",
    "        pep = str.split(i, '.')[-1]\n",
    "        pep_list.append(pep)\n",
    "\n",
    "    # extract & format protein IDs\n",
    "    id_list = []\n",
    "    for i in df.iloc[:, 1]:\n",
    "        ids = str.split(i, '(')[0]\n",
    "        id_list.append(ids)\n",
    "        \n",
    "    # make new df\n",
    "    df_fmt = pd.DataFrame()\n",
    "    df_fmt['peptide'] = pep_list\n",
    "    df_fmt['protein'] = id_list\n",
    "    \n",
    "    return(df_fmt)\n",
    "\n",
    "def unique_peps(df):\n",
    "    \n",
    "    # get protein IDs with unique peptides\n",
    "    df['num_matches'] = df['protein'].apply(lambda x: len(str.split(x, ',')))\n",
    "    df = df[df['num_matches'] == 1]\n",
    "    df_uniq = df.drop(['num_matches'], axis=1)\n",
    "    \n",
    "    return(df_uniq)\n",
    "\n",
    "def count_peps(df, frac):\n",
    "    # get peptide counts\n",
    "    counts = df.groupby(['peptide']).size().sort_values(ascending=False)\n",
    "    count_dict = dict()\n",
    "    for i in counts.items():\n",
    "        pep = i[0]\n",
    "        count = i[1]\n",
    "        count_dict[pep] = count\n",
    "        \n",
    "    # join count info back onto df\n",
    "    count_col = 'frac_count'+str(frac)\n",
    "    df[count_col] = [count_dict[i] for i in df['peptide']]\n",
    "    df_counts = df.drop_duplicates()\n",
    "    \n",
    "    return(df_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22661989-2c1c-430d-b53c-555c161558f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_36a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_49a_02172017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_01a_02172017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_31a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_22a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_27a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_58a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_15a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_45a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_40a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_10a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_56a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_17a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_42a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_39a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_02a_02172017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_60a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_35a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_05a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_48a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_50a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_41a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_37a_02172017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_07a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_46a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_16a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_55a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_09a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_57a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_52a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_43a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_53b_02212017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_18a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_14a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_44a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_59a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_11a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_23a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_26a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_13a_02172017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_24a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_30a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_28a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_54a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_06a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_47a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_12a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_03a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_51a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_08a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_20a_02192017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_34a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_33a_02202017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_38a_02182017.prot_list ...\n",
      "Processing ../ppi_ml/data/cfms/msblender/leca_level/arath/wwc_1/output/Athaliana_sproutsWWC_29a_02192017.prot_list ...\n"
     ]
    }
   ],
   "source": [
    "def process_fracs(data_dir, file_list)\n",
    "    \n",
    "    df_list = []\n",
    "    frac_count = 0\n",
    "    for f in file_list:\n",
    "        frac_count += 1\n",
    "        df_fmt = fmt_data(data_dir+f)\n",
    "        df_uniq = unique_peps(df_fmt)\n",
    "        df_counts = count_peps(df_uniq, frac_count)\n",
    "        df_list.append(df_counts)\n",
    "\n",
    "    if len(df_list) > 1:\n",
    "        df_joined = reduce(lambda x, y: pd.merge(x, y, on=['peptide', 'protein'], how='outer'), df_list)\n",
    "        df_joined.fillna(0, inplace=True)\n",
    "    else:\n",
    "        df_joined = df_list[0]\n",
    "\n",
    "    count_cols = []\n",
    "    for c in df_joined.columns:\n",
    "        if df_joined[c].dtype == float:\n",
    "            df_joined[c] = df_joined[c].astype(int)\n",
    "            count_cols.append(c)\n",
    "\n",
    "    tcol = 'total_counts'\n",
    "    df_joined[tcol] = df_joined[count_cols].sum(axis=1)\n",
    "    \n",
    "    return(df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33cf772a-8509-45ec-9aa6-fb8d7f453a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_peps(df)\n",
    "    # get experiment-wide unique peptide assignments\n",
    "    counts = df.groupby(['peptide']).size().sort_values(ascending=False)\n",
    "    bad_peps = []\n",
    "    for p in counts.items():\n",
    "        if p[1] > 1:\n",
    "            bad_peps.append(p[0])\n",
    "    df_out = df[df['peptide'].apply(lambda x: x not in bad_peps)]\n",
    "    \n",
    "    # check for errors\n",
    "    bad_pep_sum = 0\n",
    "    for c in counts.items():\n",
    "        if c[1] > 1:\n",
    "            bad_pep_sum += c[1]\n",
    "\n",
    "    actual_sum = len(df_joined) - len(df_out)\n",
    "\n",
    "    if actual_sum != bad_pep_sum:\n",
    "        print(\"Something went wrong ...\")\n",
    "    \n",
    "def write_result(df, outfile)\n",
    "    df_write = df[['peptide', 'protein', 'total_counts']]\n",
    "    df_write.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374980c4-9f1f-4025-98fe-a95dd0d5c11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "peptide\n",
       "SVQVMKTEGSTTVSLPHSAMSPVQDEER               3\n",
       "TEGSTTVSLPHSAMSPVQDEERDSGK                 3\n",
       "IREWCEQQVPYMCPDYQSYFR                      3\n",
       "MIGIWGPAGIGK                               3\n",
       "IIVRVNRPFLIAVVLKDTQSIIFLGK                 3\n",
       "                                          ..\n",
       "IAREILKQQDALFASR                           1\n",
       "IAREIGDAVIK                                1\n",
       "IAREIFKQQDALFASRPLTYAQK                    1\n",
       "IAREIEAETTRDIHVAEERGLQLNENFDFDEEARYSSVR    1\n",
       "YYYYQYLSSTSEAAEEKIAMLQENESLKK              1\n",
       "Length: 1427513, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6186da00-0883-4d68-b668-768c9d5a6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get experiment-wide unique peptide assignments\n",
    "bad_peps = []\n",
    "for p in counts.items():\n",
    "    if p[1] > 1:\n",
    "        bad_peps.append(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb64f458-55f8-4b3e-82a9-9d019e08ab40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2135"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_peps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd93140a-40e8-477e-9bc4-cdede89885be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_joined[df_joined['peptide'].apply(lambda x: x not in bad_peps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f0b631b-1bca-48de-9db7-338d037d337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_write = df_out[['peptide', 'protein', 'total_counts']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175af202-a007-4319-a050-1e961f275ee8",
   "metadata": {},
   "source": [
    "I put the above code into an argparse script (`get_pep_assignments.py`); then ran the code below on the results to get aggregate totals for each species/experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebffcce1-d096-4b48-a438-01a91ee1b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = '../ppi_ml/data/meta/euk_codes_ordered.txt'\n",
    "species = [line.strip() for line in open(fs, 'r')]\n",
    "data_dir = '../ppi_ml/data/cfms/pep_assign/'\n",
    "outdir = '../ppi_ml/data/cfms/pep_assign_totals/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5829212-05c8-4663-bcb5-892806959bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brart_sec_1.pep_assign']\n",
      "brart: 0 non-unique peps across experiments; these will be removed.\n",
      "['caeel_iex_1.pep_assign', 'caeel_beads_iex_7.pep_assign', 'caeel_beads_iex_9.pep_assign', 'caeel_beads_iex_2.pep_assign', 'caeel_iex_4.pep_assign', 'caeel_iex_3.pep_assign', 'caeel_beads_iex_5.pep_assign', 'caeel_iex_2.pep_assign', 'caeel_beads_iex_4.pep_assign', 'caeel_beads_iex_8.pep_assign', 'caeel_beads_iex_3.pep_assign', 'caeel_beads_iex_6.pep_assign', 'caeel_beads_iex_1.pep_assign']\n",
      "caeel: 5533 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dicdi_iex_1.pep_assign', 'dicdi_iex_3.pep_assign', 'dicdi_iex_2.pep_assign']\n",
      "dicdi: 922 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drome_iex_4.pep_assign', 'drome_iex_3.pep_assign', 'drome_iex_1.pep_assign', 'drome_iex_2.pep_assign']\n",
      "drome: 1417 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human_iex_12.pep_assign', 'human_iex_9.pep_assign', 'human_iex_2.pep_assign', 'human_iex_19.pep_assign', 'human_iex_23.pep_assign', 'human_ief_1.pep_assign', 'human_iex_5.pep_assign', 'human_iex_24.pep_assign', 'human_iex_15.pep_assign', 'human_iex_10.pep_assign', 'human_iex_21.pep_assign', 'human_ief_4.pep_assign', 'human_iex_7.pep_assign', 'human_ief_3.pep_assign', 'human_sucrose_1.pep_assign', 'human_ief_2.pep_assign', 'human_iex_6.pep_assign', 'human_iex_16.pep_assign', 'human_iex_11.pep_assign', 'human_sec_1.pep_assign', 'human_ief_5.pep_assign', 'human_iex_20.pep_assign', 'human_iex_1.pep_assign', 'human_iex_4.pep_assign', 'human_iex_14.pep_assign', 'human_sucrose_2.pep_assign', 'human_iex_13.pep_assign', 'human_iex_8.pep_assign', 'human_iex_22.pep_assign', 'human_iex_3.pep_assign', 'human_iex_18.pep_assign']\n",
      "human: 9298 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mouse_iex_2.pep_assign', 'mouse_iex_3.pep_assign', 'mouse_sec_1.pep_assign', 'mouse_iex_1.pep_assign']\n",
      "mouse: 1225 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nemve_iex_5.pep_assign', 'nemve_iex_2.pep_assign', 'nemve_iex_1.pep_assign', 'nemve_iex_6.pep_assign', 'nemve_iex_3.pep_assign', 'nemve_iex_4.pep_assign']\n",
      "nemve: 2458 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pig_iex_1.pep_assign']\n",
      "pig: 0 non-unique peps across experiments; these will be removed.\n",
      "['strpu_iex_1.pep_assign', 'strpu_iex_6.pep_assign', 'strpu_iex_3.pep_assign', 'strpu_iex_8.pep_assign', 'strpu_wwc_1.pep_assign', 'strpu_iex_4.pep_assign', 'strpu_iex_5.pep_assign', 'strpu_iex_2.pep_assign', 'strpu_iex_9.pep_assign', 'strpu_iex_7.pep_assign', 'strpu_iex_10.pep_assign']\n",
      "strpu: 3591 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xenla_sucrose_4.pep_assign', 'xenla_sec_1.pep_assign', 'xenla_iex_1.pep_assign', 'xenla_sucrose_3.pep_assign', 'xenla_sec_3.pep_assign', 'xenla_sucrose_1.pep_assign', 'xenla_sec_2.pep_assign', 'xenla_sucrose_2.pep_assign']\n",
      "xenla: 3740 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yeast_iex_1.pep_assign']\n",
      "yeast: 0 non-unique peps across experiments; these will be removed.\n",
      "['euggr_sec_1.pep_assign']\n",
      "euggr: 0 non-unique peps across experiments; these will be removed.\n",
      "['tryb2_sec_1.pep_assign', 'tryb2_sax_1.pep_assign', 'tryb2_sec_2.pep_assign']\n",
      "tryb2: 1591 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['phatc_iex_1.pep_assign', 'phatc_sec_1.pep_assign']\n",
      "phatc: 797 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plaba_bng_2.pep_assign', 'plaba_bng_1.pep_assign', 'plaba_bng_3.pep_assign']\n",
      "plaba: 1177 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plaf7_bng_9.pep_assign', 'plaf7_bng_5.pep_assign', 'plaf7_iex_2.pep_assign', 'plaf7_bng_7.pep_assign', 'plaf7_bng_6.pep_assign', 'plaf7_iex_1.pep_assign', 'plaf7_bng_4.pep_assign', 'plaf7_bng_8.pep_assign', 'plaf7_wwc_1.pep_assign']\n",
      "plaf7: 6119 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plakh_bng_13.pep_assign', 'plakh_bng_14.pep_assign', 'plakh_bng_11.pep_assign', 'plakh_bng_10.pep_assign', 'plakh_bng_15.pep_assign', 'plakh_bng_12.pep_assign']\n",
      "plakh: 2745 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tetts_iex_1.pep_assign', 'tetts_sec_1.pep_assign', 'tetts_sec_3.pep_assign', 'tetts_iex_xlink_1.pep_assign', 'tetts_iex_2.pep_assign', 'tetts_sec_2.pep_assign']\n",
      "tetts: 4980 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arath_iex_5.pep_assign', 'arath_iex_2.pep_assign', 'arath_iex_1.pep_assign', 'arath_sec_1.pep_assign', 'arath_iex_3.pep_assign', 'arath_wwc_1.pep_assign', 'arath_iex_4.pep_assign']\n",
      "arath: 4484 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['braol_iex_1.pep_assign', 'braol_sec_1.pep_assign', 'braol_wwc_1.pep_assign', 'braol_ief_1.pep_assign']\n",
      "braol: 2666 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cansa_iex_1.pep_assign']\n",
      "cansa: 0 non-unique peps across experiments; these will be removed.\n",
      "['cerri_wwc_1.pep_assign', 'cerri_sec_1.pep_assign']\n",
      "cerri: 15772 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheqi_iex_1.pep_assign']\n",
      "cheqi: 0 non-unique peps across experiments; these will be removed.\n",
      "['chlre_sec_2.pep_assign', 'chlre_sec_xlink_2.pep_assign', 'chlre_sec_xlink_1.pep_assign', 'chlre_sec_1.pep_assign', 'chlre_wwc_1.pep_assign']\n",
      "chlre: 2920 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cocnu_sec_1.pep_assign']\n",
      "cocnu: 0 non-unique peps across experiments; these will be removed.\n",
      "['maize_sec_1.pep_assign']\n",
      "maize: 0 non-unique peps across experiments; these will be removed.\n",
      "['orysj_sec_1.pep_assign', 'orysj_iex_1.pep_assign', 'orysj_iex_2.pep_assign']\n",
      "orysj: 1024 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['selml_wwc_1.pep_assign', 'selml_sec_1.pep_assign']\n",
      "selml: 817 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sollc_iex_1.pep_assign']\n",
      "sollc: 0 non-unique peps across experiments; these will be removed.\n",
      "['soybn_sec_2.pep_assign', 'soybn_sec_xlink_1.pep_assign', 'soybn_sec_1.pep_assign']\n",
      "soybn: 1568 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wheat_sec_3.pep_assign', 'wheat_iex_1.pep_assign', 'wheat_sec_2.pep_assign', 'wheat_ief_1.pep_assign']\n",
      "wheat: 1068 non-unique peps across experiments; these will be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/164211787.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n"
     ]
    }
   ],
   "source": [
    "for s in species:\n",
    "    pep_assign_files = [f for f in os.listdir(data_dir) if re.match(s, f)]\n",
    "    print(pep_assign_files)\n",
    "    df_list = []\n",
    "    for f in pep_assign_files:\n",
    "        df = pd.read_csv(data_dir+f, sep=',')\n",
    "        ncol = f.replace('.pep_assign', '')\n",
    "        df.columns.values[2] = ncol+'_counts'\n",
    "        df_list.append(df)\n",
    "    \n",
    "    if len(df_list) > 1:\n",
    "        final_df = reduce(lambda x, y: pd.merge(x, y, on=['peptide', 'protein'], how='outer'), df_list)\n",
    "        final_df.fillna(0, inplace=True)\n",
    "    else:\n",
    "        final_df = df\n",
    "    \n",
    "    count_cols = []\n",
    "    for c in final_df.columns:\n",
    "        if final_df[c].dtype == float:\n",
    "            final_df[c] = final_df[c].astype(int)\n",
    "            count_cols.append(c)\n",
    "    \n",
    "    counts = final_df.groupby(['peptide']).size().sort_values(ascending=False)\n",
    "    bad_peps = []\n",
    "    for p in counts.items():\n",
    "        if p[1] > 1:\n",
    "            bad_peps.append(p[0])\n",
    "    print(f'{s}: {len(bad_peps)} non-unique peps across experiments; these will be removed.')\n",
    "    df_out = final_df[final_df['peptide'].apply(lambda x: x not in bad_peps)]\n",
    "    \n",
    "    tcol = s+'_total'\n",
    "    df_out[tcol] = df_out[count_cols].sum(axis=1).astype(int)\n",
    "    \n",
    "    outfile = outdir+s+'_pep_assign_totals.csv'\n",
    "    df_out.to_csv(outfile, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
